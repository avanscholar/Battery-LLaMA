{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cfNhXScZPt7",
    "outputId": "948e02fe-a0c4-4239-dfbe-2bccf74e1231"
   },
   "outputs": [],
   "source": [
    "!pip install crossref\n",
    "!pip install elsapy\n",
    "!pip install xmltodict\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JLfnfT2edAfk",
    "outputId": "a8bb1158-87cb-4c51-bc26-5d73778487d0"
   },
   "outputs": [],
   "source": [
    "#Elsevier Libraries\n",
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "\n",
    "#Libraries for URL access\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import pprint\n",
    "import requests\n",
    "import xmltodict\n",
    "import urllib3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "#Import warnings library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#xml.etree.ElementTree â€” The ElementTree XML API\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "info_list = [] #Creating an empty list to store the  info\n",
    "#Rerunning this will delete the data that will be stored further\n",
    "#Run only once\n",
    "\n",
    "#Create a num array of 0 to 5900 spaces 100 apart per page. Each page of Search returns 100 entries until 6000 is reached\n",
    "num = np.linspace(0, 5900, 60, dtype = int)\n",
    "print(num)\n",
    "#Maximum of 6000 searches are returned on calling the ElsSearch API\n",
    "\n",
    "#Append \"apikey\" and \"insttoken\" as suggest in the ElsSearch document into a config file\n",
    "config = {\"apikey\": \"Enter your API\", \"insttoken\": \"Enter the inst token\"}\n",
    "\n",
    "client = ElsClient(config['apikey'])\n",
    "client.inst_token = config['insttoken']\n",
    "\n",
    "def XML_DOI(link):\n",
    "\n",
    "    #defining a header's dictionary to pass through requests\n",
    "    headers_dict = {\"X-ELS-APIKey\": \"2dc442325fc67f2f275ec3157ef8df65\", \"X-ELS-Insttoken\": \"6beb1f6c29d85f50029bf11c8de94d1b\", \"Accept\": \"application/xml\"}\n",
    "\n",
    "    #x takes response of the HTTP request, passes link\n",
    "    x = requests.get(link, headers=headers_dict)\n",
    "\n",
    "    #Save it as XML file\n",
    "    with open(\"doi.xml\", 'wb') as f:\n",
    "        f.write(x.content)\n",
    "\n",
    "link_list = []\n",
    "\n",
    "#Loop to iterate over all papers\n",
    "#UPI query can take many arguments.\n",
    "#start, count, query are a few as name suggests\n",
    "for i in range(len(num)):\n",
    "\n",
    "    start = \"https://api.elsevier.com/content/search/sciencedirect?\"\n",
    "    count = \"start=\" + str(num[i]) + \"&count=100\"\n",
    "    query = \"&query=Sustainable+Battery+Recycling\"\n",
    "    endapi = \"&apiKey=Enter your API key&insttoken=Enter your inst key\"\n",
    "    link = start + count + query  + endapi\n",
    "    #print(link)\n",
    "    link_list.append(link)\n",
    "#subscription = \"&subscribed=true\"\n",
    "\n",
    "link_list[6]\n",
    "\n",
    "# Call the XML_DOI function\n",
    "\n",
    "for j in range(len(link_list)):\n",
    "    xmlfile = XML_DOI(link_list[j])\n",
    "    #Read the data\n",
    "    #<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    tree = ET.parse('/content/doi.xml')\n",
    "    root = tree.getroot()\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "\n",
    "        info_dict = {} #This will create a dictionary where we will store information about the searches\n",
    "\n",
    "        '''\n",
    "        CHECK CODE\n",
    "        url = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text\n",
    "        title = entry.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "        pub_name = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text\n",
    "        doi = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi').text\n",
    "        #description = entry.find('{http://purl.org/dc/elements/1.1/}description').text\n",
    "        print(url, title, pub_name, doi)\n",
    "        print('\\n')\n",
    "        '''\n",
    "\n",
    "        info_dict['URL'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text\n",
    "        info_dict['Title'] = entry.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "        info_dict['Pub_Name'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text\n",
    "        doi = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi')\n",
    "        if doi is None:\n",
    "            info_dict['DOI'] = None\n",
    "        else:\n",
    "            info_dict['DOI'] = doi.text\n",
    "\n",
    "        info_list.append(info_dict)\n",
    "\n",
    "# %% [code]\n",
    "type(info_list), len(info_list)\n",
    "\n",
    "print(len(info_list))\n",
    "\n",
    "# %% [code]\n",
    "DOI =  []\n",
    "Title = []\n",
    "Pub_name = []\n",
    "\n",
    "for i in range(len(info_list)):\n",
    "    DOI.append(info_list[i]['DOI'])\n",
    "    Title.append(info_list[i]['Title'])\n",
    "    Pub_name.append(info_list[i]['Pub_Name'])\n",
    "\n",
    "# %% [code]\n",
    "df =  pd.DataFrame()\n",
    "df['Title'] =  Title\n",
    "df['Pub_name'] = Pub_name\n",
    "df['DOI'] = DOI\n",
    "\n",
    "df.head()\n",
    "\n",
    "# %% [code]\n",
    "#Create string1 and string2 to join doi with institoken to make a single URL\n",
    "string1 = \"https://api.elsevier.com/content/article/doi/\"\n",
    "string2 = \"?apiKey=Enter your API key&insttoken=Enter your inst key\"\n",
    "\n",
    "#Access every DOI in the previous file and append the new URL to another column\n",
    "df['Link'] = df['DOI'].apply(lambda x: string1 + str(x) + string2)\n",
    "\n",
    "df.head()\n",
    "\n",
    "list_abstract = []\n",
    "list_doi= []\n",
    "list_title = []\n",
    "list_date = []\n",
    "list_journal = []\n",
    "\n",
    "from pprint import pprint\n",
    "doi= df['DOI']\n",
    "for i in range(len(info_list)):\n",
    "    doi = info_list[i]['DOI']\n",
    "    if doi is not None:\n",
    "        doi_doc = FullDoc(doi = doi)\n",
    "        if doi_doc.read(client):\n",
    "\n",
    "            #pprint(dir(doi_doc))\n",
    "            #pprint(doi_doc._data)\n",
    "            abstract = doi_doc._data['coredata']['dc:description']\n",
    "            title = doi_doc.title\n",
    "            date = doi_doc._data['coredata']['prism:coverDisplayDate']\n",
    "            journal = doi_doc._data['coredata']['prism:publicationName']\n",
    "            #pprint(abstract)\n",
    "            #print(i, 'done')\n",
    "            #dict_abstract['DOI'] = doi[i]\n",
    "            #dict_abstract['Abstract'] = abstract\n",
    "            list_abstract.append(abstract)\n",
    "            list_doi.append(doi)\n",
    "            list_title.append(title)\n",
    "            list_date.append(date)\n",
    "            list_journal.append(journal)\n",
    "            #doi_doc.write()\n",
    "        else:\n",
    "            pprint('Operation failed')\n",
    "            list_abstract.append('0')\n",
    "            list_doi.append('1')\n",
    "            list_title.append('2')\n",
    "            list_date.append('3')\n",
    "            list_journal.append('4')\n",
    "    else:\n",
    "        list_abstract.append('0')\n",
    "        list_doi.append('1')\n",
    "        list_title.append('2')\n",
    "        list_date.append('3')\n",
    "        list_journal.append('4')\n",
    "\n",
    "# %% [code]\n",
    "df_available_abstract = pd.DataFrame()\n",
    "df_available_abstract['DOI'] = list_doi\n",
    "df_available_abstract['Title'] = list_title\n",
    "df_available_abstract['Abstract'] = list_abstract\n",
    "df_available_abstract['Date'] = list_date\n",
    "df_available_abstract['Journal'] = list_journal\n",
    "\n",
    "df_available_abstract.head(len(info_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JiB1cTTnqHCT"
   },
   "outputs": [],
   "source": [
    "df_available_abstract.to_csv(\"Enter address\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
